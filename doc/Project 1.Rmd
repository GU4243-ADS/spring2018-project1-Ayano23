---
title: "notes"
author: "Ayano Kase"
date: "February 4, 2018"
output: pdf_document
---

## Setup the libraries
First we want to install and load libraries we need along the way.  Note that the following code is completely reproducible -- you don't need to add any code on your own to make it run.

```{r, message = F, warning = F}
packages.used <- c("ggplot2", "dplyr", "tibble", "tidyr",  "stringr", "tidytext", "topicmodels", "wordcloud", "ggridges","ggraph","igraph")

# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))

# install additional packages
if(length(packages.needed) > 0) {
  install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}

library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(tidytext)
library(ggridges)
library(ggraph)
library(igraph)

```

## Read in the data
The following code assumes that the dataset `spooky.csv` lives in a `data` folder (and that we are inside a `docs` folder).

```{r}
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
```

Let's first remind ourselves of the structure of the data.
```{r}
head(spooky)
summary(spooky)
```

We see from the above that each row of our data contains a unique ID, a single sentence text excerpt, and an abbreviated author name. `HPL` is Lovecraft, `MWS` is Shelly, and `EAP` is Poe.  We finally note that there are no missing values, and we change author name to be a factor variable, which will help us later on.

```{r}
sum(is.na(spooky))
spooky$author <- as.factor(spooky$author)
```


## Bigrams

First thing we will try is to extract pairs of words that the authors use often and map it out.


```{r}
#extract pairs using unnest_tokens
bigram_spooky <- select(spooky,author, text) 
bigram_spooky <- unnest_tokens(bigram_spooky,bigram, text, token = "ngrams", n = 2)
sample_n(bigram_spooky, 5)

#filter out stop_words
#seprate the bigrams, filter the words, and unite them back 
bi_sep <- separate(bigram_spooky, bigram, c("word1", "word2"), sep = " ")

bi_filt <- filter(bi_sep, !word1 %in% stop_words$word) 
bi_filt <- filter(bi_filt, !word2 %in% stop_words$word)

bigram_counts <- count(bi_filt, word1, word2, sort = TRUE)

bigram_spooky <- unite(bi_filt, bigram, word1, word2, sep = " ")

```

```{r, include=FALSE}
#extract tf-idf values 
frequency <- count(bigram_spooky, author, bigram)
tf_idf    <- bind_tf_idf(frequency, bigram, author, n)
head(tf_idf)
tail(tf_idf)
tf_idf    <- arrange(tf_idf, desc(tf_idf))

tf_idf    <- mutate(tf_idf, bigram = factor(bigram, levels = rev(unique(bigram))))
tf_idf <- group_by(tf_idf, author)

# Grab the top ten tf_idf scores in all the words 
tf_idf_10 <- top_n(tf_idf,10,tf_idf)
ungroup(tf_idf_10)

# plot the bigrams with highest tf-idf values per author
png("../figs/Bigram.png")
ggplot(tf_idf_10) +
  geom_col(aes(bigram, tf_idf, fill = author)) +
  labs(x = NULL, y = "TF-IDF values") +
  theme(legend.position = "top", axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9))+
  facet_wrap(~ author, ncol = 3, scales = "free") +
  coord_flip()
dev.off()
```

# Next, we will make a network plot for each individual author. 

```{r}
# create a function that would produce network plot for each author
# input parameters: author, minimum count for bigram graph
plot_bigram_net_author <- function(name, bimin){

  filt <- filter(bigram_spooky, author == name)

  sep <- separate(filt, bigram, c("word1", "word2"), sep = " ")
  
  #filter for stop words
  bi_filt <- filter(sep, !word1 %in% stop_words$word)
  bi_filt <- filter(bi_filt, !word2 %in% stop_words$word)
  
  bigram_graph <- count(bi_filt, word1, word2, sort = TRUE) 
  bigram_graph <- filter(bigram_graph, n > bimin)
  bigram_graph <- graph_from_data_frame(bigram_graph)
  
  set.seed(1234)

  a <- grid::arrow(type = "closed", length = unit(.08, "inches"))
  
  # graph the network plot
  ggraph(bigram_graph, layout = "fr") +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
    geom_node_point(color = "pink", size = 2) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
    theme_void()
}

```

```{r, include=FALSE}
png("../figs/network_EAP.png")
plot_bigram_net_author("EAP",4)
dev.off()

png("../figs/network_HPL.png")
plot_bigram_net_author("HPL",4)
dev.off()

png("../figs/network_MWS.png")
plot_bigram_net_author("MWS",3)
dev.off()
```

## 2. Punctuation analysis
# Authors have different writing styles. Thus we want to analyze their use of punctuations. We look at the author's use of five types of punctuation marks: commas, question marks, colons, semi-colons, and quotation marks. 

```{r, include=FALSE}
# filter text data by author and store in new vector
EAP <- filter(spooky, author == "EAP")$text
HPL <- filter(spooky, author == "HPL")$text
MWS <- filter(spooky, author == "MWS")$text

# count the number of each punctuation for each author and store them in a vector
punc_EAP <- c(sum(str_count(EAP,',')),sum(str_count(EAP,'[?]')),sum(str_count(EAP,'[:]')),sum(str_count(EAP,';')),sum(str_count(EAP,'["]')))
punc_HPL <- c(sum(str_count(HPL,',')),sum(str_count(HPL,'[?]')),sum(str_count(HPL,'[:]')),sum(str_count(HPL,';')),sum(str_count(HPL,'["]')))
punc_MWS <- c(sum(str_count(MWS,',')),sum(str_count(MWS,'[?]')),sum(str_count(MWS,'[:]')),sum(str_count(MWS,';')),sum(str_count(MWS,'["]')))

#create a dataframe
punc_value <- c(punc_EAP, punc_HPL, punc_MWS)
punc_type <- c("comma","questionmark","colon","semicolon","quotation","comma","questionmark","colon","semicolon","quotation","comma","questionmark","colon","semicolon","quotation")
punc_type <- as.factor(punc_type)
authors <- c("EAP","EAP","EAP","EAP","EAP","HPL","HPL","HPL","HPL","HPL","MWS","MWS","MWS","MWS","MWS")
punc <- data.frame(punc_value, punc_type, authors)
punc

punc$punc_type <- factor(punc$punc_type, levels = punc$punc_type[order(punc$punc_value)])

png("../figs/punc_bargraph.png")
ggplot(data = punc, aes(x=authors,y=punc_value, fill = punc_type, order = -as.numeric(punc_type)))+
  geom_bar(stat = "identity")
dev.off()

```

```{r}
# calculate the avergae number of each puctuation mark in a sentence
avgpunc_EAP <- round(punc_EAP/length(EAP),2)
avgpunc_HPL <- round(punc_HPL/length(HPL),2)
avgpunc_MWS <- round(punc_MWS/length(MWS),2)
```

## 3. Sentiment Analysis 
# Here, we will focus on negative sentiments. 

```{r}
# filter stopwords and drop punctuations
spooky_wrd <- unnest_tokens(spooky, word, text)
spooky_wrd <- anti_join(spooky_wrd, stop_words, by = "word")

# using the nrc sentiment lexicon, filter only for the negative words
nrc_neg <- filter(get_sentiments('nrc'), sentiment == "negative")
nrc_neg

# join the list of negative words with spooky-wrd
negative <- inner_join(spooky_wrd, nrc_neg, by = "word")
head(negative)
count(negative, word, sort = TRUE)
```

Now we plot a frequency comparison of these "negative" words.  Namely, we show the frequencies of the overall most frequently-used negative words compared among the three authors. 

```{r, include=FALSE}
pos_words     <- count(group_by(negative, word, author))
pos_words_all <- count(group_by(negative, word))

pos_words <- left_join(pos_words, pos_words_all, by = "word")
pos_words <- arrange(pos_words, desc(n.y))
pos_words <- ungroup(head(pos_words, 81))


png("../figs/negative.png")
ggplot(pos_words) +
  geom_col(aes(reorder(word, n.y, FUN = min), n.x, fill = author)) +
  xlab(NULL) +
  coord_flip() +
  facet_wrap(~ author) +
  theme(legend.position = "none")
dev.off()
```

The above analysis, however, did not take into account negated negatives, such as "not good". The next analysis will allow us to compare the occurences of positive and negative words preceded by the word "not".

```{r, include=FALSE}
# filter through bigram procedure
bi_sep <- select(spooky, author, text)
bi_sep <- unnest_tokens(bi_sep, bigram, text, token = "ngrams", n = 2)
bi_sep <- separate(bi_sep,bigram, c("word1", "word2"), sep = " ")

# all authors
a <- filter(bi_sep, word1 == "not")
a <- inner_join(a, get_sentiments("afinn"), by = c(word2 = "word")) 
a <- count(a, word1, word2, score, sort = TRUE)
a <- ungroup(a)
a <- mutate(a, contribution = n * score)
a <- arrange(a, desc(abs(contribution))) 
a <- head(a,15)
a <- mutate(a, word2 = reorder(word2, contribution))

png("../figs/a.png")
ggplot(a, aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("") +
  ylab("Sentiment score * number of occurrences") +
  coord_flip() +
  theme(plot.title = element_text(size=11)) +
  ggtitle("All authors - Words preceded by the term 'not'")
dev.off()

# EAP
b <- filter(bi_sep, author == "EAP")
b <- filter(b, word1 == "not")
b <- inner_join(b, get_sentiments("afinn"), by = c(word2 = "word"))
b <- count(b, word1, word2, score, sort = TRUE)
b <- ungroup(b)
b <- mutate(b, contribution = n * score)
b <- arrange(b, desc(abs(contribution)))
b <- head(b, 15)
b <- mutate(b,word2 = reorder(word2, contribution))

png("../figs/b.png")
ggplot(b, aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("") +
  ylab("Sentiment score * number of occurrences") +
  coord_flip() +
  theme(plot.title = element_text(size=11)) +
  ggtitle("EAP - Words preceded by the term 'not'")
dev.off()

# HPL
c <- filter(bi_sep, author == "HPL")
c <- filter(c, word1 == "not")
c <- inner_join(c,get_sentiments("afinn"), by = c(word2 = "word"))
c <- count(c, word1, word2, score, sort = TRUE)
c <- ungroup(c)
c <- mutate(c, contribution = n * score)
c <- arrange(c, desc(abs(contribution)))
c <- head(c, 15)
c <- mutate(c, word2 = reorder(word2, contribution))

png("../figs/c.png")
ggplot(c, aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("") +
  ylab("Sentiment score * number of occurrences") +
  coord_flip() +
  theme(plot.title = element_text(size=11)) +
  ggtitle("HPL - Words preceded by the term 'not'")
dev.off()

# MWS
d <- filter(bi_sep, author == "MWS")
d <- filter(d, word1 == "not")
d <- inner_join(d, get_sentiments("afinn"), by = c(word2 = "word"))
d <- count(d, word1, word2, score, sort = TRUE)
d <- ungroup(d)
d <- mutate(d, contribution = n * score)
d <- arrange(d, desc(abs(contribution)))
d <- head(d, 15)
d <- mutate(d, word2 = reorder(word2, contribution))

png("../figs/d.png")
ggplot(d, aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("") +
  ylab("Sentiment score * number of occurrences") +
  coord_flip() +
  theme(plot.title = element_text(size=11)) +
  ggtitle("MWS - Words preceded by the term 'not'")
dev.off()

```



